{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_advanced_segmentation_models as tasm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "    \n",
    "def round_clip_0_1(x, **kwargs):\n",
    "    return x.round().clip(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define heavy augmentations\n",
    "def get_training_augmentation(height, width):\n",
    "    train_transform = [\n",
    "\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        A.ShiftScaleRotate(scale_limit=0.6, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        A.PadIfNeeded(min_height=height, min_width=width, always_apply=True, border_mode=0),\n",
    "        A.RandomCrop(height=height, width=width, always_apply=True),\n",
    "\n",
    "        A.IAAAdditiveGaussianNoise(p=0.2),\n",
    "        A.IAAPerspective(p=0.5),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CLAHE(p=1),\n",
    "                A.RandomBrightness(p=1),\n",
    "                A.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.IAASharpen(p=1),\n",
    "                A.Blur(blur_limit=3, p=1),\n",
    "                A.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomContrast(p=1),\n",
    "                A.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        A.Lambda(mask=round_clip_0_1)\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation(height, width):\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        A.PadIfNeeded(height, width),\n",
    "        A.Resize(height, width, always_apply=True)\n",
    "    ]\n",
    "    return A.Compose(test_transform)\n",
    "\n",
    "def data_get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Asi deberia de ser###############\n",
    "#Total_classes = ['Rocks','Terrain','People','Building','Robot','Sky','Trees','Station S','WhatEver']\n",
    "#N_total_classes = 9\n",
    "############################################\n",
    "Total_classes = ['Rocks','Terrain','People','Building','Robot','Sky','Trees','Station S','WhatEver','noKnow','noKnow2']\n",
    "N_total_classes = 11\n",
    "\n",
    "Classes_pixel_count_dict = {\"Rocks\":346,'Terrain':818301,'People':15709988,'Building':140525,'Robot':250492,\n",
    "                            'Sky':807478,'Trees':4485973,'Station S':2201037,'WhatEver':2733,'noKnow':123848,\n",
    "                            'noKnow2':35279}\n",
    "\n",
    "\n",
    "MODEL_CLASSES = Total_classes\n",
    "ALL_CLASSES = False\n",
    "if MODEL_CLASSES == Total_classes:\n",
    "    ALL_CLASSES = True\n",
    "\n",
    "batch_size = 4\n",
    "N_classes = len(Total_classes)\n",
    "height = 480\n",
    "width = 640\n",
    "backbone_name = \"efficientnetb3\"\n",
    "weights = \"imagenet\"\n",
    "wwo_aug = True # train data with and without augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to calculate appropriate class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      inf 2.730e+00 1.400e-01 1.595e+01 8.910e+00 2.760e+00 5.000e-01\n",
      " 1.010e+00 9.090e+02 1.818e+01 6.493e+01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SEBAST~1\\AppData\\Local\\Temp/ipykernel_6504/1079971839.py:40: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  class_weights = np.round(mean_pixel_frequency / pixel_frequency, 2)\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Class Weights\n",
    "################################################################################\n",
    "def get_dataset_counts(d):\n",
    "    pixel_count = np.array([i for i in d.values()])\n",
    "\n",
    "    sum_pixel_count = 0\n",
    "    for i in pixel_count:\n",
    "        sum_pixel_count += i\n",
    "\n",
    "    return pixel_count, sum_pixel_count\n",
    "\n",
    "def get_dataset_statistics(pixel_count, sum_pixel_count):\n",
    "    \n",
    "    pixel_frequency = np.round(pixel_count / sum_pixel_count, 4)\n",
    "\n",
    "    mean_pixel_frequency = np.round(np.mean(pixel_frequency), 4)\n",
    "\n",
    "    return pixel_frequency, mean_pixel_frequency\n",
    "\n",
    "def get_balancing_class_weights(classes, d):\n",
    "    pixel_count, sum_pixel_count = get_dataset_counts(d)\n",
    "\n",
    "    background_pixel_count = 0\n",
    "    mod_pixel_count = []\n",
    "\n",
    "    for c in Total_classes:\n",
    "        if c not in classes:\n",
    "            background_pixel_count += d[c]\n",
    "        else:\n",
    "            mod_pixel_count.append(d[c])\n",
    "\n",
    "    if not ALL_CLASSES:\n",
    "        mod_pixel_count.append(background_pixel_count)\n",
    "    else:\n",
    "        mod_pixel_count[:-1]\n",
    "    \n",
    "    pixel_frequency, mean_pixel_frequency = get_dataset_statistics(mod_pixel_count, sum_pixel_count)\n",
    "\n",
    "    class_weights = np.round(mean_pixel_frequency / pixel_frequency, 2)\n",
    "    return class_weights    \n",
    "\n",
    "class_weights = get_balancing_class_weights(MODEL_CLASSES, Classes_pixel_count_dict)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Data Generator\n",
    "################################################################################\n",
    "def create_image_label_path_generator(images_dir, masks_dir, shuffle=False, seed=None):\n",
    "    ids = sorted(os.listdir(images_dir))\n",
    "    mask_ids = sorted(os.listdir(masks_dir))\n",
    "\n",
    "    if shuffle == True:\n",
    "\n",
    "        if seed is not None:\n",
    "            tf.random.set_seed(seed)\n",
    "\n",
    "        indices = tf.range(start=0, limit=tf.shape(ids)[0], dtype=tf.int32)\n",
    "        shuffled_indices = tf.random.shuffle(indices)\n",
    "\n",
    "        ids = tf.gather(ids, shuffled_indices).numpy().astype(str)\n",
    "        mask_ids = tf.gather(mask_ids, shuffled_indices).numpy().astype(str)\n",
    "\n",
    "    images_fps = [os.path.join(images_dir, image_id) for image_id in ids]\n",
    "    masks_fps = [os.path.join(masks_dir, image_id) for image_id in mask_ids]\n",
    "\n",
    "    while True:\n",
    "        for i in range(len(images_fps)):\n",
    "            yield [images_fps[i], masks_fps[i]]\n",
    "\n",
    "\n",
    "def process_image_label(images_paths, masks_paths, classes, augmentation=None, preprocessing=None, all_classes=False):\n",
    "    class_values = [Total_classes.index(cls.lower()) for cls in classes]\n",
    "    \n",
    "    # read data\n",
    "    image = cv2.imread(images_paths)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(masks_paths, 0)\n",
    "\n",
    "    # extract certain classes from mask (e.g. cars)\n",
    "    masks = [(mask == v) for v in class_values]\n",
    "    mask = np.stack(masks, axis=-1).astype('float')\n",
    "    \n",
    "    # add background if mask is not binary\n",
    "    if mask.shape[-1] != 1 and not all_classes:\n",
    "        background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "        mask = np.concatenate((mask, background), axis=-1)\n",
    "    \n",
    "    # apply augmentations\n",
    "    if augmentation:\n",
    "        sample = augmentation(image=image, mask=mask)\n",
    "        image, mask = sample['image'], sample['mask']\n",
    "    \n",
    "    # apply preprocessing\n",
    "    if preprocessing:\n",
    "        sample = preprocessing(image=image, mask=mask)\n",
    "        image, mask = sample['image'], sample['mask']\n",
    "\n",
    "    # mask = np.squeeze(np.argmax(mask, axis=-1))\n",
    "    # mask = np.argmax(mask, axis=-1)\n",
    "    # mask = mask[..., np.newaxis]\n",
    "        \n",
    "    return image, mask\n",
    "\n",
    "def DataGenerator(train_dir, label_dir, batch_size, height, width, classes, augmentation, all_classes=False, wwo_aug=False, shuffle=False, seed=None):\n",
    "    image_label_path_generator = create_image_label_path_generator(\n",
    "        train_dir, label_dir, shuffle=shuffle, seed=seed\n",
    "    )\n",
    "    if wwo_aug:\n",
    "        while True:\n",
    "            images = np.zeros(shape=[batch_size, height, width, 3])\n",
    "            if all_classes:\n",
    "                labels = np.zeros(shape=[batch_size, height, width, len(classes)], dtype=np.float32)\n",
    "            else:\n",
    "                labels = np.zeros(shape=[batch_size, height, width, len(classes) + 1], dtype=np.float32)\n",
    "            for i in range(0, batch_size, 2):\n",
    "                image_path, label_path = next(image_label_path_generator)\n",
    "                image_aug, label_aug = process_image_label(image_path, label_path, classes=classes, augmentation=augmentation, all_classes=all_classes)\n",
    "                image_wo_aug, label_wo_aug = process_image_label(image_path, label_path, classes=classes, augmentation=get_validation_augmentation(height=HEIGHT, width=WIDTH), all_classes=all_classes)\n",
    "                images[i], labels[i] = image_aug, label_aug\n",
    "                images[i + 1], labels[i + 1] = image_wo_aug, label_wo_aug\n",
    "\n",
    "            yield tf.convert_to_tensor(images), tf.convert_to_tensor(labels, tf.float32)\n",
    "    else:\n",
    "        while True:\n",
    "            images = np.zeros(shape=[batch_size, height, width, 3])\n",
    "            if all_classes:\n",
    "                labels = np.zeros(shape=[batch_size, height, width, len(classes)], dtype=np.float32)\n",
    "            else:\n",
    "                labels = np.zeros(shape=[batch_size, height, width, len(classes) + 1], dtype=np.float32)\n",
    "            for i in range(batch_size):\n",
    "                image_path, label_path = next(image_label_path_generator)\n",
    "                image, label = process_image_label(image_path, label_path, classes=classes, augmentation=augmentation, all_classes=all_classes)\n",
    "                images[i], labels[i] = image, label\n",
    "\n",
    "            yield tf.convert_to_tensor(images), tf.convert_to_tensor(labels, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "43941888/43941136 [==============================] - 10s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model, layers, layer_names = tasm.create_base_model(name=backbone_name, weights=weights, height=height, width=width, include_top=False, pooling=None)\n",
    "\n",
    "BACKBONE_TRAINABLE = False\n",
    "model = tasm.DANet(n_classes=N_classes, base_model=base_model, output_layers=layers, backbone_trainable=BACKBONE_TRAINABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the optimizer as well as losses, metrics and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.2, momentum=0.9)\n",
    "metrics = [tasm.metrics.IOUScore(threshold=0.5)]\n",
    "categorical_focal_dice_loss = tasm.losses.CategoricalFocalLoss(alpha=0.25, gamma=2.0) + tasm.losses.DiceLoss(class_weights=class_weights)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=categorical_focal_dice_loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "model.run_eagerly = True\n",
    "\n",
    "callbacks = [\n",
    "            #  tf.keras.callbacks.ModelCheckpoint(\"DeepLabV3plus.ckpt\", verbose=1, save_weights_only=True, save_best_only=True),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(monitor=\"iou_score\", factor=0.2, patience=6, verbose=1, mode=\"max\"),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor=\"iou_score\", patience=16, mode=\"max\", verbose=1, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shuffle = True\n",
    "val_shuffle = True\n",
    "seed = 29598\n",
    "\n",
    "TrainSetwwoAug = DataGenerator(\n",
    "    x_train_dir,\n",
    "    y_train_dir,\n",
    "    batch_size,\n",
    "    height,\n",
    "    width,\n",
    "    classes=MODEL_CLASSES,\n",
    "    augmentation=get_training_augmentation(height=height, width=width),\n",
    "    all_classes=ALL_CLASSES,\n",
    "    wwo_aug=True,\n",
    "    shuffle=train_shuffle,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "ValidationSet = DataGenerator(\n",
    "    x_valid_dir,\n",
    "    y_valid_dir,\n",
    "    1,\n",
    "    height,\n",
    "    width,\n",
    "    classes=MODEL_CLASSES,\n",
    "    augmentation=get_validation_augmentation(height=height, width=width),\n",
    "    all_classes=ALL_CLASSES,\n",
    "    shuffle=val_shuffle,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "TestSet = DataGenerator(\n",
    "    x_test_dir,\n",
    "    y_test_dir,\n",
    "    1,\n",
    "    height,\n",
    "    width,\n",
    "    classes=MODEL_CLASSES,\n",
    "    augmentation=get_validation_augmentation(height=height, width=width),\n",
    "    all_classes=ALL_CLASSES,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "for i in TrainSetwwoAug:\n",
    "    sample_image, sample_mask = i[0][0], i[1][0]\n",
    "    print(len(i))\n",
    "    print(i[0].shape)\n",
    "    print(i[1].shape)\n",
    "    break\n",
    "\n",
    "print(len(os.listdir(x_train_dir)))\n",
    "print(len(os.listdir(x_valid_dir)))\n",
    "print(len(os.listdir(x_test_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SEBAST~1\\AppData\\Local\\Temp/ipykernel_6504/309153197.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# K.one_hot(K.squeeze(output_mask, axis=-1), 3)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mshow_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\SEBAST~1\\AppData\\Local\\Temp/ipykernel_6504/309153197.py\u001b[0m in \u001b[0;36mshow_predictions\u001b[1;34m(dataset, num)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshow_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0moutput_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;31m# print(output_model.numpy())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_image' is not defined"
     ]
    }
   ],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    \n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    output_model = model(sample_image[tf.newaxis, ...])\n",
    "    # print(output_model.numpy())\n",
    "    \n",
    "    output_mask = create_mask(output_model)\n",
    "    # print(sample_mask.shape)\n",
    "\n",
    "    scce = tf.keras.losses.CategoricalCrossentropy()\n",
    "    print(\"SparseCategoricalCrossentroy: \" + str(scce(sample_mask, output_model[0]).numpy()))\n",
    "    # print(iou_score(sample_mask, output_model[0]))\n",
    "    print(\"Iou-Score: \" + str(tasm.losses.iou_score(sample_mask[tf.newaxis, ...], output_model, class_weights=class_weights).numpy()))\n",
    "    # print(\"Dice Loss: \" + str(dice_loss(sample_mask, output_model[0]).numpy()))\n",
    "    # print(\"Categorical Focal Loss: \" + str(categorical_focal_loss(sample_mask, output_model[0]).numpy()))\n",
    "    print(\"categorical Focal Dice Loss: \" + str(categorical_focal_dice_loss(sample_mask[tf.newaxis, ...], output_model).numpy()))\n",
    "    \n",
    "    display([sample_image, tf.argmax(sample_mask, axis=-1)[..., tf.newaxis], output_mask]) # K.one_hot(K.squeeze(output_mask, axis=-1), 3)])\n",
    "    \n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up_sampling2d: True\n",
      "model: True\n",
      "convolution_bn_activation: True\n",
      "convolution_bn_activation_1: True\n",
      "pam__module: True\n",
      "cam__module: True\n",
      "convolution_bn_activation_5: True\n",
      "convolution_bn_activation_6: True\n",
      "dropout: True\n",
      "dropout_1: True\n",
      "dropout_2: True\n",
      "convolution_bn_activation_7: True\n",
      "convolution_bn_activation_8: True\n",
      "convolution_bn_activation_9: True\n",
      "concatenate_1: True\n",
      "concatenate_2: True\n",
      "convolution_bn_activation_10: True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if \"functional\" in layer.name:\n",
    "        layer.trainable = False\n",
    "\n",
    "    print(layer.name + \": \" + str(layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac4f8bbfdd6c92fa8fceb90cf46ad666e2f84d188bd5b2dcaa5835f477e81f4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tfSegmentation2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
